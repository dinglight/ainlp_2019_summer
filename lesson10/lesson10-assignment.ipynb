{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using word2vec + fully connected neural networks to finish “豆瓣评论” classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (0,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>comment</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>吴京意淫到了脑残的地步，看了恶心想吐</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>中二得很</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                        link name  \\\n",
       "0  1  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "1  2  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "2  3  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "3  4  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "4  5  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "\n",
       "                                             comment star  \n",
       "0                                 吴京意淫到了脑残的地步，看了恶心想吐    1  \n",
       "1  首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...    2  \n",
       "2  吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋...    2  \n",
       "3                      凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。    4  \n",
       "4                                               中二得很    1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "fname = 'movie_comments.csv'\n",
    "df = pd.read_csv(fname, encoding='utf8')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261497, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 删除comment为空的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261495, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[pd.notnull(df['comment'])]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 删除comment重复的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213970, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(['comment'], inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 使用jieba对comment分词生成word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import jieba\n",
    "\n",
    "def comment_to_word_tokens(comment):\n",
    "    if not isinstance(comment,str):\n",
    "        print(comment)\n",
    "        return\n",
    "    \n",
    "    #print(type(comment))\n",
    "    pattern = re.compile('[\\u4E00-\\u9FA5]')\n",
    "    only_chinese = pattern.findall(comment)\n",
    "    chinese_comment = ''.join(only_chinese)\n",
    "    chinese_tokens = jieba.cut(chinese_comment)\n",
    "    word_tokens = ' '.join(chinese_tokens)\n",
    "    if word_tokens == '':\n",
    "        return None\n",
    "    return word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\DINGLI~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.076 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "df['word_tokens'] = df['comment'].apply(comment_to_word_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 删除word_tokens 为空的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208486, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[pd.notnull(df['word_tokens'])]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 重建索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = range(df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 检查评分数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_star_count(count_star):\n",
    "    plt.figure(figsize=(12,4))\n",
    "    sns.barplot(count_star.index, count_star.values, alpha=0.8)\n",
    "    plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "    plt.xlabel('Star', fontsize=12)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAucAAAEJCAYAAAA3oYmnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xu0XWV57/HvzwCK9QJIREpQUOMFPRUxBFo9VlEhqD3QUz2FKqRIjReo2npOxXYoCtKqtdJ6jqVCiYR6AeqlRIrFVKUOrVyCIgiIRECJ3ILhImJR4Dl/rDfdq5udZJLstdfaWd/PGHOsOZ/5vnM962UwePbkne9MVSFJkiRp+B427AQkSZIk9VicS5IkSSPC4lySJEkaERbnkiRJ0oiwOJckSZJGhMW5JEmSNCIsziVJkqQRYXEuSZIkjQiLc0mSJGlEbDXsBIZpxx13rN12223YaUiSJGkLdskll9xWVXO7tB3r4ny33XZj5cqVw05DkiRJW7AkP+za1mktkiRJ0oiwOJckSZJGxIwU50kekeSiJN9JckWS97b4aUmuS3Jp2/Zs8ST5SJJVSS5LslfftRYnuaZti/viz0tyeevzkSSZid8mSZIkTZeZmnN+L7BfVd2dZGvg60m+2M79n6r6zKT2BwLz27YPcBKwT5IdgGOBBUABlyRZXlW3tzZLgAuAc4FFwBeRJEmSZokZuXNePXe3w63bVhvochBweut3AbBdkp2BA4AVVbW2FeQrgEXt3GOq6ptVVcDpwMED+0GSJEnSAMzYnPMkc5JcCtxKr8C+sJ06oU1dOTHJw1tsF+CGvu6rW2xD8dVTxKfKY0mSlUlWrlmzZrN/lyRJkjRdZqw4r6r7q2pPYB6wMMmzgXcCzwD2BnYA3tGaTzVfvDYhPlUeJ1fVgqpaMHdup+UmJUmSpBkx46u1VNUdwPnAoqq6qU1duRf4OLCwNVsN7NrXbR5w40bi86aIS5IkSbPGjDwQmmQu8MuquiPJtsBLgQ8k2bmqbmorqxwMfLd1WQ4cneQMeg+E3tnanQf8eZLtW7v9gXdW1dokP02yL3AhcDjwfzc139f+zT9vateR9om3vmLYKUiSJGkDZmq1lp2BZUnm0Ltbf1ZVnZPkK61wD3Ap8MbW/lzg5cAq4B7gCIBWhB8PXNzaHVdVa9v+m4DTgG3prdLiSi2SJEmaVWakOK+qy4DnThHfbz3tCzhqPeeWAkuniK8Enr15mUqSJEnD4xtCJUmSpBFhcS5JkiSNCItzSZIkaURYnEuSJEkjwuJckiRJGhEW55IkSdKIsDiXJEmSRoTFuSRJkjQiLM4lSZKkEWFxLkmSJI0Ii3NJkiRpRGw17AQ02m4+5XeHncJAPOH1Zw47BUmSpAfxzrkkSZI0IizOJUmSpBFhcS5JkiSNCItzSZIkaURYnEuSJEkjwuJckiRJGhEW55IkSdKIsDiXJEmSRoTFuSRJkjQiZqQ4T/KIJBcl+U6SK5K8t8V3T3JhkmuSnJlkmxZ/eDte1c7v1netd7b41UkO6IsvarFVSY6Zid8lSZIkTaeZunN+L7BfVT0H2BNYlGRf4APAiVU1H7gdOLK1PxK4vaqeCpzY2pFkD+AQ4FnAIuBvk8xJMgf4KHAgsAdwaGsrSZIkzRozUpxXz93tcOu2FbAf8JkWXwYc3PYPase08y9JkhY/o6rurarrgFXAwratqqprq+oXwBmtrSRJkjRrzNic83aH+1LgVmAF8APgjqq6rzVZDezS9ncBbgBo5+8EHtcfn9RnffGp8liSZGWSlWvWrJmOnyZJkiRNixkrzqvq/qraE5hH7073M6dq1j6znnMPNT5VHidX1YKqWjB37tyNJy5JkiTNkE0qzpNsu+7hzYeqqu4Azgf2BbZLslU7NQ+4se2vBnZt37UV8FhgbX98Up/1xSVJkqRZo1NxnuRDSRa2/VfQK5TvSPJbHfvPTbJd298WeClwFfBV4FWt2WLg7La/vB3Tzn+lqqrFD2mruewOzAcuAi4G5rfVX7ah99Do8i65SZIkSaNiq403AeA1wLvb/ruB19KbB34i8IUO/XcGlrVVVR4GnFVV5yS5EjgjyfuAbwOntvanAv+QZBW9PwQOAaiqK5KcBVwJ3AccVVX3AyQ5GjgPmAMsraorOv42SZIkaSR0Lc4fWVX3JHkc8OSq+ixAkid16VxVlwHPnSJ+Lb3555Pj/wG8ej3XOgE4YYr4ucC5XfKRJEmSRlHX4vz7SV4DPJXeSisk2RH4+aASkyRJksZN1+L8zcDfAL8EXtdiBwBfGkRSkiRJ0jjqVJxX1cXAb0yKfRL45CCSkiRJksZR56UUk7wsyalJvtCOFyTZb3CpSZIkSeOl61KKfwicBFwDvLCFfw68b0B5SZIkSWOn653ztwEvrar3Aw+02PeApw8kK0mSJGkMdS3OHw3c0ParfW4N/GLaM5IkSZLGVNfi/GvAMZNib6H3hk9JkiRJ06DrUop/CHwhyeuBRye5GrgL+K2BZSZJkiSNma5LKd6UZG9gb+BJ9Ka4XFRVD2y4pyRJkqSuOhXnSfYEflJVFwEXtdiuSXaoqu8MMkFpVLzuzNdtvNEstPR3lw47BUmS1HSdc/4Jeg+A9tsG+IfpTUeSJEkaX12L8ydW1bX9gar6AbDbtGckSZIkjamuxfnqJHv1B9rxjdOfkiRJkjSeuq7WciJwdpIPAj8AngL8b+CEQSUmSZIkjZuuq7WckuQO4EhgV3qrtby9qj4zyOQkSZKkcdL1zjlV9Y/APw4wF0mSJGmsdS7Ok+wP7Ak8qj9eVe+e7qQkSZKkcdR1nfP/B/wv4KvAPX2nahBJSZIkSeOo653zQ4E9q+qGQSYjSZIkjbOuSyn+BLhjkIlIkiRJ465rcf5XwCeT/HqSJ/dvXTon2TXJV5NcleSKJG9t8fck+XGSS9v28r4+70yyKsnVSQ7oiy9qsVVJjumL757kwiTXJDkzyTYdf5skSZI0ErpOazmpfb5yUryAOR3630dv6cVvJXk0cEmSFe3ciVX1of7GSfYADgGeBfwq8K9JntZOfxR4GbAauDjJ8qq6EvhAu9YZSf6O3rKPJyFJkiTNEl3XOe96h319/W8Cbmr7P01yFbDLBrocBJxRVfcC1yVZBSxs51ZV1bUASc4ADmrX2w/4vdZmGfAeLM6lgbjk9UuGncJAPO+Uk4edgiRpzD2kortNT9l3c74wyW7Ac4ELW+joJJclWZpk+xbbhd6LjtZZ3WLriz8OuKOq7psUn+r7lyRZmWTlmjVrNuenSJIkSdOq61KKTwQ+TW+d8wIeleRVwKKq+oOuX5bkUcBngbdV1V1JTgKOb9c8nt7c9tcBmaJ7MfUfE7WB9g8OVp0MnAywYMECl4KUtFnOPPFrw05hIH73j1447BQkaSx1vXP+MeCfgUcDv2yxFfTmfneSZGt6hfknq+pzAFV1S1XdX1UPAKcwMXVlNbBrX/d5wI0biN8GbJdkq0lxSZIkadboWpwvBN7fiugCqKo7gcd26ZwkwKnAVVX14b74zn3Nfhv4bttfDhyS5OFJdgfmAxcBFwPz28os29B7aHR5VRW9FyS9qvVfDJzd8bdJkiRJI6Hrai23AE8Fvr8u0FZU+VHH/s8HDgMuT3Jpi/0pcGiSdVNlrgfeAFBVVyQ5C7iS3kovR1XV/e17jwbOo7dKzNKquqJd7x3AGUneB3yb3h8DkiRJ0qzRtTj/EHBOkr8AtkpyKL3i+v1dOlfV15l6Xvi5G+hzAnDCFPFzp+rXVnBZODkuSZIkzRZdl1JcmmQtsITeaimHA++qqn8aZHKSJEnSONlocZ5kDnAscILFuCRJkjQ4G30gtM31PoqJVVokSZIkDUDX1VqWAW8cZCKSJEnSuOv6QOhC4A+T/Am9Oef/+fKeqvJNFZIkSdI06Fqcn9I2SZIkSQPS9YHQp9B7IPTewackSZIkjScfCJUkSZJGhA+ESpIkSSPCB0IlSZKkEeEDoZIkSdKI6FScV9WyQSciSZIkjbtOxXmS163vXFUtnb50JEmSpPHVdVrLYZOOn0BvecVvABbnkiRJ0jToOq3lxZNj7W76M6c9I0mSJGlMdV1KcSqnAUdOUx6SJEnS2Os653xyEf9I4LXAHdOekSRpVjr1XX8y7BQG4sjjPzjsFCSNka5zzu+jb23z5sfAkulNR5IkSRpfXYvz3Scd/6yqbpvuZCRJkqRx9lDunN9TVbevCyTZHti2qm4cSGaSJEnSmOn6QOg/AfMmxeYBn5/edCRJkqTx1bU4f3pVXd4faMfP6NI5ya5JvprkqiRXJHlri++QZEWSa9rn9i2eJB9JsirJZUn26rvW4tb+miSL++LPS3J56/ORJOn42yRJkqSR0LU4vzXJU/sD7fgnHfvfB7y9qp4J7AsclWQP4Bjgy1U1H/hyOwY4EJjftiXASe07dwCOBfYBFgLHrivoW5slff0WdcxNkiRJGgldi/OlwGeTvDLJHkl+C/gM8PddOlfVTVX1rbb/U+AqYBfgIGBZa7YMOLjtHwScXj0XANsl2Rk4AFhRVWvb/PcVwKJ27jFV9c2qKuD0vmtJkiRJs0LXB0LfD/wS+BCwK/Aj4FTgww/1C5PsBjwXuBDYqapugl4Bn+TxrdkuwA193Va32Ibiq6eIT/X9S2hLQD7xiU98qOlLkiRJA9OpOK+qB4C/bNsmS/Io4LPA26rqrg1MC5/qRG1C/MHBqpOBkwEWLFgwZRtJkiRpGDpNa0lyTJK9J8UWJun8OrgkW9MrzD9ZVZ9r4VvalBTa560tvpreHfp15gE3biQ+b4q4JEmSNGt0nXP+VuDKSbErgbd16dxWTjkVuKqq+qfCLAfWrbiyGDi7L354W7VlX+DONv3lPGD/JNu3B0H3B85r536aZN/2XYf3XUuSJEmaFbrOOd+G3pzzfr8AHtGx//OBw4DLk1zaYn9Kby77WUmOpDeP/dXt3LnAy4FVwD3AEQBVtTbJ8cDFrd1xVbW27b8JOA3YFvhi2yRJkqRZo2txfgnwZuCv+2JvBL7VpXNVfZ2p54UDvGSK9gUctZ5rLaW3eszk+Erg2V3ykSRJkkZR1+L8j4AVSQ4DfgA8FdgJeNmgEpMkSZLGTdfVWq5I8jTglfQeyPwccE5V3T3I5CRJkqRx0vXOOcDOwA+BS6rqmgHlI0mSJI2tja7WkuR/JrkeuBr4BvC9JNcnedWgk5MkSZLGyQaL8ySvAD4O/C3wZHoroTwFOAn4+ySvHHiGkiRJ0pjY2LSWdwFvqKoz+mLXAx9I8qN2/pwB5SZJkiSNlY1Na3kW8Pn1nPscsMf0piNJkiSNr40V5/cCj1nPue3ovYhIkiRJ0jTYWHH+L8BfrOfcnwPnTW86kiRJ0vja2JzzdwBfT3IZ8FngJnpLKv4OvTvqLxhsepIkSdL42GBxXlU/TrIX8MfAImBH4DbgbODEqlo7+BQlSZKk8bDRlxBV1e30VmV51+DTkSRJksbXRl9CJEmSJGlmWJxLkiRJI8LiXJIkSRoR6y3Ok1zQt3/szKQjSZIkja8N3Tl/WpJHtP23z0QykiRJ0jjb0GotZwPfT3I9sG2Sr03VqKpeOIjEJEmSpHGz3uK8qo5I8gJgN2Bv4NSZSkqSJEkaRxt7CdHX6b0hdJuqWjZDOUmSJEljaaMvIQKoqqVJXgwcBuwC/Bj4RFV9ZZDJSZIkSeOk01KKSf4AOBO4GfgccBPwqSSv79h/aZJbk3y3L/aeJD9OcmnbXt537p1JViW5OskBffFFLbYqyTF98d2TXJjkmiRnJtmmS16SJEnSKOm6zvmfAC+rqj+tqo9V1Z8B+7d4F6cBi6aIn1hVe7btXIAkewCHAM9qff42yZwkc4CPAgcCewCHtrYAH2jXmg/cDhzZMS9JkiRpZHQtzh8HXDkpdjWwQ5fOVfU1YG3H7zoIOKOq7q2q64BVwMK2raqqa6vqF8AZwEFJAuwHfKb1XwYc3PG7JEmSpJHRtTj/OvDhJI8ESPIrwF8C/76Z3390ksvatJftW2wX4Ia+NqtbbH3xxwF3VNV9k+JTSrIkycokK9esWbOZ6UuSJEnTp2tx/kbg14A7k9wC3AE8B3jDZnz3ScBTgD3pzWH/qxbPFG1rE+JTqqqTq2pBVS2YO3fuQ8tYkiRJGqCuq7XcBPxmknnArwI3VtXqzfniqrpl3X6SU4Bz2uFqYNe+pvOAG9v+VPHbgO2SbNXunve3lyRJkmaNrnfOAaiq1VV10eYW5gBJdu47/G1g3Uouy4FDkjw8ye7AfOAi4GJgfluZZRt6D40ur6oCvgq8qvVfTO/tppIkSdKs0unO+eZK8mngRcCOSVYDxwIvSrInvSko19OmyFTVFUnOovcA6n3AUVV1f7vO0cB5wBxgaVVd0b7iHcAZSd4HfBvfZipJkqRZaEaK86o6dIrwegvoqjoBOGGK+LnAuVPEr6W3moskSZI0a210WkuShyXZzxf7SJIkSYO10eK8qh4Azm5ri0uSJEkakK4PhH4tyb4DzUSSJEkac13nnP8Q+GKSs+m9COg/1xGvqncPIjFJkiRp3HQtzrcF/qntzxtQLpIkSdJY6/oSoiMGnYgkSZI07jovpZjkmfRe9LNTVR2d5OnAw6vqsoFlJ0mSJI2RTg+EJnk18DVgF+DwFn408OEB5SVJkiSNna6rtRwHvKyq3gjc32LfAZ4zkKwkSZKkMdS1OH88vWIcJlZqqb59SZIkSZupa3F+CXDYpNghwEXTm44kSZI0vro+EPoW4EtJjgR+Jcl5wNOA/QeWmSRJkjRmui6l+L0kzwBeCZxD70VE51TV3YNMTpIkSRonnZdSrKp7knwDuA640cJckiRJml6divMkTwQ+CewL3A5sn+RC4DVV9cMB5idJ0qxz3akXDzuFgdj9yL2HnYK0xev6QOgyeg+FbldVjwe2By5ucUmSJEnToOu0lucB+1fVLwGq6u4k7wB+MrDMJEnSrPexj31s2CkMxBve8IZhp6AtVNc75xcACyfFFgDfnN50JEmSpPG13jvnSY7rO/wBcG6Sf6a3UsuuwMuBTw02PUmSJGl8bGhay66Tjj/XPh8P3At8HnjEIJKSJEmSxtF6i/OqOmImE5EkSZLGXdc55yR5ZJJfS/Ib/VvHvkuT3Jrku32xHZKsSHJN+9y+xZPkI0lWJbksyV59fRa39tckWdwXf16Sy1ufjyRJ198lSZIkjYpOxXmSw4Gbga8AZ/ZtZ3T8ntOARZNixwBfrqr5wJfbMcCBwPy2LQFOajnsABwL7EPv4dRj1xX0rc2Svn6Tv0uSJEkaeV2XUvwg8DtVtWJTvqSqvpZkt0nhg4AXtf1lwPnAO1r89Koq4IIk2yXZubVdUVVrAZKsABYlOR94TFV9s8VPBw4GvrgpuUqSJA3Cin89fNgpDMTLXnr6sFPYonSd1vILesXzdNqpqm4CaJ+Pb/Fd6K0Is87qFttQfPUU8SklWZJkZZKVa9as2ewfIUmSJE2XrsX5u4APJ9lxkMk0U80Xr02IT6mqTq6qBVW1YO7cuZuYoiRJkjT9uk5r+T5wHPDmvmctA1RVzdnE774lyc5VdVObtnJri6/mvy7jOA+4scVfNCl+fovPm6K9JEmSRtChX94y32P56Zf8+mZfo+ud838ATgeeAzytbfPb56ZaDqxbcWUxcHZf/PC2asu+wJ1t2st5wP5Jtm8Pgu4PnNfO/TTJvm2VlsP7riVJkiTNGl3vnD8OeHd7SPMhS/Jpene9d0yymt6qK+8HzkpyJPAj4NWt+bn03j66CrgHOAKgqtYmOR64uLU7bt3DocCb6K0Isy29B0F9GFSSJEmzTtfi/OPAYfTunj9kVXXoek69ZIq2BRy1nussBZZOEV8JPHtTcpMkSZJGRdfifCFwdJI/A27pP1FVL5z2rCRJkqQx1LU4P6VtkiRJkgakU3FeVcsGnYgkSZI07joV50let75zbR64JEmSpM3UdVrLYZOOnwA8BfgGUzygKUmSJOmh6zqt5cWTY+1u+jOnPSNJkiRpTHV9CdFUTgOOnKY8JEmSpLHXdc755CL+kcBrgTumPSNJkiRpTHWdc34fMPntoD8GXj+96UiSJEnjq2txvvuk459V1W3TnYwkSZI0zro+EPrDQSciSZIkjbsNFudJvsqDp7P0q6p6yfSmJEmSJI2njd05/8R64rsAb6H3YKgkSZKkabDB4ryqTu0/TvI44J30HgQ9EzhucKlJkiRJ46XTOudJHpPkeGAVsBOwV1UtqarVA81OkiRJGiMbLM6TbJvkncC19N4G+oKqOqyqfjAj2UmSJEljZGNzzq8D5gAfBFYCOyXZqb9BVX1lQLlJkiRJY2Vjxfl/0Fut5U3rOV/Ak6c1I0mSJGlMbeyB0N1mKA9JkiRp7HV6IFSSJEnS4FmcS5IkSSNi6MV5kuuTXJ7k0iQrW2yHJCuSXNM+t2/xJPlIklVJLkuyV991Frf21yRZPKzfI0mSJG2qoRfnzYuras+qWtCOjwG+XFXzgS+3Y4ADgfltWwKcBL1iHjgW2AdYCBy7rqCXJEmSZotRKc4nOwhY1vaXAQf3xU+vnguA7ZLsDBwArKiqtVV1O7ACWDTTSUuSJEmbYxSK8wK+lOSSJEtabKequgmgfT6+xXcBbujru7rF1hd/kCRLkqxMsnLNmjXT+DMkSZKkzbOxdc5nwvOr6sYkjwdWJPneBtpmilhtIP7gYNXJwMkACxYsmLKNJEmSNAxDv3NeVTe2z1uBz9ObM35Lm65C+7y1NV8N7NrXfR5w4wbikiRJ0qwx1OI8ya8kefS6fWB/4LvAcmDdiiuLgbPb/nLg8LZqy77AnW3ay3nA/km2bw+C7t9ikiRJ0qwx7GktOwGfT7Iul09V1b8kuRg4K8mRwI+AV7f25wIvB1YB9wBHAFTV2iTHAxe3dsdV1dqZ+xmSJEnS5htqcV5V1wLPmSL+E+AlU8QLOGo911oKLJ3uHCVJkqSZMvQ555IkSZJ6LM4lSZKkEWFxLkmSJI0Ii3NJkiRpRFicS5IkSSPC4lySJEkaERbnkiRJ0oiwOJckSZJGhMW5JEmSNCIsziVJkqQRYXEuSZIkjQiLc0mSJGlEWJxLkiRJI8LiXJIkSRoRFueSJEnSiLA4lyRJkkaExbkkSZI0IizOJUmSpBFhcS5JkiSNCItzSZIkaURYnEuSJEkjYosqzpMsSnJ1klVJjhl2PpIkSdJDscUU50nmAB8FDgT2AA5Nssdws5IkSZK622KKc2AhsKqqrq2qXwBnAAcNOSdJkiSps1TVsHOYFkleBSyqqj9ox4cB+1TV0ZPaLQGWtMOnA1fPaKIPtiNw25BzGBWOxQTHYoJjMcGxmOBYTHAsJjgWExyLCaMwFk+qqrldGm416ExmUKaIPegvj6o6GTh58Ol0k2RlVS0Ydh6jwLGY4FhMcCwmOBYTHIsJjsUEx2KCYzFhto3FljStZTWwa9/xPODGIeUiSZIkPWRbUnF+MTA/ye5JtgEOAZYPOSdJkiSpsy1mWktV3ZfkaOA8YA6wtKquGHJaXYzMFJsR4FhMcCwmOBYTHIsJjsUEx2KCYzHBsZgwq8Zii3kgVJIkSZrttqRpLZIkSdKsZnEuSZIkjQiLc0mSJGlEWJwPWZLTh53DqBjnsUiyMMnebX+PJH+c5OXDzmsYHAtJ0jjbYlZrmQ2STF7aMcCLk2wHUFX/Y+azGg7HYkKSY4EDga2SrAD2Ac4Hjkny3Ko6YZj5zSTHYv2SvABYCHy3qr407HyGadzHIskzgF2AC6vq7r74oqr6l+FlNvMcC22JXK1lBiX5FnAl8Pf03l4a4NP01mSnqv5teNnNLMdiQpLLgT2BhwM3A/Oq6q4k29L7D86vDTXBGeRYTEhyUVUtbPuvB44CPg/sD3yhqt4/zPxmkmMxIclb6P3+q+j9u/LWqjq7nftWVe01zPxmkmPRTZIjqurjw85jFMyWsXBay8xaAFwC/BlwZ1WdD/y8qv5tnIrRxrGYcF9V3V9V9wA/qKq7AKrq58ADw01txjkWE7bu218CvKyq3kuvIH3NcFIaGsdiwuuB51XVwcCLgHcleWs7l6FlNRyORTfvHXYCI2RWjIXTWmZQVT0AnJjkH9vnLYzpPwPH4r/4RZJHtoL0eeuCSR7L+BWkjsWEhyXZnt5NlFTVGoCq+lmS+4ab2oxzLCbMWTd9o6quT/Ii4DNJnsT4FaSORZPksvWdAnaayVyGbUsYi3EthoaqqlYDr07yCuCuYeczTI4FAC+sqnvhP/9oWWdrYPFwUhoax2LCY+n936UAleQJVXVzkkcxZoUHjkW/m5PsWVWXAlTV3UleCSwF/ttwU5txjsWEnYADgNsnxQP8+8ynM1Szfiyccy5Js0iSRwI7VdV1w85l2MZxLJLMozf96+Ypzj2/qr4xhLSGwrGYkORU4ONV9fUpzn2qqn5vCGkNxZYwFhbnkiRJ0ojwgVBJkiRpRFicS5IkSSPC4lySJEkaERbnkiSSvCDJvye5M8naJN9IsneS30/yoAerJEmD4VKKkjTmkjwGOAd4E3AWsA3w34F7p+HaW1XVuK1FLkmbzDvnkqSnAVTVp9sbWn9eVV8Cfgn8HfDrSe5OcgdAklck+XaSu5LckOQ96y6UZLckleTIJD8CvjKE3yNJs5bFuSTp+8D9SZYlObC9jZOqugp4I/DNqnpUVW3X2v8MOBzYDngF8KYkB0+65m8Cz6T3MhBJUkcW55I05qrqLuAFQAGnAGuSLE8y5auuq+r8qrq8qh6oqsuAT9Mrxvu9p6p+VlU/H2jykrSFsTiXJFFVV1XV71fVPODZwK8Cfz1V2yT7JPlqkjVJ7qR3d33HSc1uGGzGkrRlsjiXJP0XVfU94DR6RfpUr5H+FLAc2LWqHktvXnomX2aQOUrSlsriXJLGXJJnJHl7knnteFfgUOAC4BZgXpJt+ro8GlhbVf+RZCHwezOetCRtoSzOJUk/BfYBLkzyM3pF+XeBt9NbbeUK4OYkt7X2bwaOS/JT4N30ll+UJE2DVPl/HiVJkqRR4J1zSZIkaURYnEuSJEkjwuJckiRJGhEW55IkSdKIsDiXJElCZStgAAAAH0lEQVSSRoTFuSRJkjQiLM4lSZKkEWFxLkmSJI2I/w/iXchnJtKZ/wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_star_count(df['star'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 整理评分数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_str_list = ['0', '1', '2', '3', '4', '5']\n",
    "for i in range(len(num_str_list)):\n",
    "    df.loc[df['star'] == num_str_list[i], 'star'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_star_count(df['star'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 数据平衡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_counts = df['star'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_per_class = star_counts.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie2 = make_banlance_samples(df, 2, size_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19873,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie2.index = range(serie2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    前半段 剥茧抽丝 看上去 倒 是 不雷人 黄子 韬 表现 也 还行 但是 结局 还是 很 中...\n",
       "1             缺 了 阿兰 里克 曼 这样 的 亮点 反派 这片 的 文戏 简直 是 一泡 乌\n",
       "2            除了 堆积 现代 特技 故事 干瘪 演员 能力 有限 男主是 韩国 还是 中国 呀\n",
       "3                                   老套 的 电影 怎么 会 是 年 的\n",
       "4                          跟 九层 妖塔 没 区别 舒淇 港腔 太重 容易 出戏\n",
       "Name: word_tokens, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_class_list = df['star'].unique().tolist()\n",
    "star_class_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "print(star_class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "star_2\n"
     ]
    }
   ],
   "source": [
    "star = 'star_{}'.format(2)\n",
    "print(star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_banlance_samples(df, star_class, size_per_class):\n",
    "    tmp_ser = df['word_tokens'][df['star'] == star_class]\n",
    "    if tmp_ser.shape[0] > size_per_class:\n",
    "        tmp_ser = tmp_ser.sample(n=size_per_class, random_state=42)\n",
    "    tmp_ser.index = range(tmp_ser.shape[0])\n",
    "    #tmp_ser.name = 'star_{}'.format(star_class)\n",
    "    return tmp_ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_df(df, star_class_list, size_per_class):\n",
    "    new_df = pd.DataFrame()\n",
    "    for star_class in star_class_list:\n",
    "        star_ser = make_banlance_samples(df, star_class, size_per_class)\n",
    "        #star = 'star_{}'.format(star_class)\n",
    "        new_df = pd.concat([new_df, pd.DataFrame(star_ser)], axis=1, ignore_index=True)\n",
    "        #new_df = new_df.append(make_banlance_samples(df, star_class, size_per_class))\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = merge_df(df, star_class_list, size_per_class)\n",
    "new_df.columns=['star_1', 'star_2', 'star_3', 'star_4','star_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_1</th>\n",
       "      <th>star_2</th>\n",
       "      <th>star_3</th>\n",
       "      <th>star_4</th>\n",
       "      <th>star_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>吴京 意淫 到 了 脑残 的 地步 看 了 恶心 想 吐</td>\n",
       "      <td>前半段 剥茧抽丝 看上去 倒 是 不雷人 黄子 韬 表现 也 还行 但是 结局 还是 很 中...</td>\n",
       "      <td>场景 文艺 爱情 文艺</td>\n",
       "      <td>机油 搞笑 不能 因为 烂 名字 错过 的</td>\n",
       "      <td>美好 的 小事</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>中二得 很</td>\n",
       "      <td>缺 了 阿兰 里克 曼 这样 的 亮点 反派 这片 的 文戏 简直 是 一泡 乌</td>\n",
       "      <td>我 觉得 这种 咨询 顾问 不 可能 有效</td>\n",
       "      <td>对于 这样 的 经典 我 在 抱 有 充分 尊重 的 同时 也 习惯于 带 着 质疑 去 欣...</td>\n",
       "      <td>反过来 的 非常 突然</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>犯 我 中华 者 虽远必 诛 吴京 比 这句 话 还要 意淫 一百倍</td>\n",
       "      <td>除了 堆积 现代 特技 故事 干瘪 演员 能力 有限 男主是 韩国 还是 中国 呀</td>\n",
       "      <td>看到 后面 才 说出 这 其实 是 旅游 广告片 么 里面 的 主旨 是 有 的 略 矫情 ...</td>\n",
       "      <td>重温 原来 第一站 那么 好看 场面 精彩 流畅 大气 情绪 渲染 到位 配乐 十分 燃 剧...</td>\n",
       "      <td>大师</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>吴京 的 冷峰 在 这部 里 即 像 成龙 又 像杰 森斯坦 森但 体制 外 的 同 类型 ...</td>\n",
       "      <td>老套 的 电影 怎么 会 是 年 的</td>\n",
       "      <td>大 隐隐 于市</td>\n",
       "      <td>女人 也 可以 不 依靠 任何人 而活 的 很 好 当然 这 取决于 她 自身 对 爱情 友...</td>\n",
       "      <td>李安 把 中西文化 结合 的 恰到好处 做足 了 细节 相比之下 前期 作品 更 打动 人</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>犯 我 中华 者 虽远必 诛 是 有 多 无脑 才 信 这句 话</td>\n",
       "      <td>跟 九层 妖塔 没 区别 舒淇 港腔 太重 容易 出戏</td>\n",
       "      <td>我 好像 不是 很 喜欢 这个 姑娘 啊</td>\n",
       "      <td>制作 非常 好 不过 剧情 太 日本</td>\n",
       "      <td>感动 落泪</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              star_1  \\\n",
       "0                       吴京 意淫 到 了 脑残 的 地步 看 了 恶心 想 吐   \n",
       "1                                              中二得 很   \n",
       "2                 犯 我 中华 者 虽远必 诛 吴京 比 这句 话 还要 意淫 一百倍   \n",
       "3  吴京 的 冷峰 在 这部 里 即 像 成龙 又 像杰 森斯坦 森但 体制 外 的 同 类型 ...   \n",
       "4                   犯 我 中华 者 虽远必 诛 是 有 多 无脑 才 信 这句 话   \n",
       "\n",
       "                                              star_2  \\\n",
       "0  前半段 剥茧抽丝 看上去 倒 是 不雷人 黄子 韬 表现 也 还行 但是 结局 还是 很 中...   \n",
       "1           缺 了 阿兰 里克 曼 这样 的 亮点 反派 这片 的 文戏 简直 是 一泡 乌   \n",
       "2          除了 堆积 现代 特技 故事 干瘪 演员 能力 有限 男主是 韩国 还是 中国 呀   \n",
       "3                                 老套 的 电影 怎么 会 是 年 的   \n",
       "4                        跟 九层 妖塔 没 区别 舒淇 港腔 太重 容易 出戏   \n",
       "\n",
       "                                              star_3  \\\n",
       "0                                        场景 文艺 爱情 文艺   \n",
       "1                              我 觉得 这种 咨询 顾问 不 可能 有效   \n",
       "2  看到 后面 才 说出 这 其实 是 旅游 广告片 么 里面 的 主旨 是 有 的 略 矫情 ...   \n",
       "3                                            大 隐隐 于市   \n",
       "4                               我 好像 不是 很 喜欢 这个 姑娘 啊   \n",
       "\n",
       "                                              star_4  \\\n",
       "0                              机油 搞笑 不能 因为 烂 名字 错过 的   \n",
       "1  对于 这样 的 经典 我 在 抱 有 充分 尊重 的 同时 也 习惯于 带 着 质疑 去 欣...   \n",
       "2  重温 原来 第一站 那么 好看 场面 精彩 流畅 大气 情绪 渲染 到位 配乐 十分 燃 剧...   \n",
       "3  女人 也 可以 不 依靠 任何人 而活 的 很 好 当然 这 取决于 她 自身 对 爱情 友...   \n",
       "4                                 制作 非常 好 不过 剧情 太 日本   \n",
       "\n",
       "                                          star_5  \n",
       "0                                        美好 的 小事  \n",
       "1                                    反过来 的 非常 突然  \n",
       "2                                             大师  \n",
       "3  李安 把 中西文化 结合 的 恰到好处 做足 了 细节 相比之下 前期 作品 更 打动 人  \n",
       "4                                          感动 落泪  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('douban.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 从词向量到句向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 加载训练好的word2vec 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "zh_wiki_word2vec_model = Word2Vec.load('../lesson04/cbow_word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zh_wiki_word2vec_model.vector_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3.2 sentence embedding\n",
    " \n",
    " A Simple but Tough-to-Beat Baseline for Sentence Embeddings\n",
    " ref： https://github.com/PrincetonML/SIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_frequency(word, model):\n",
    "    try:\n",
    "        freq = model.wv.vocab[word].count\n",
    "    except KeyError:\n",
    "        freq = 1.0\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vector(word, model):\n",
    "    try:\n",
    "        vec = model[word]\n",
    "    except KeyError:\n",
    "        vec = np.zeros(model.vector_size)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_vec(sentence_list, word2vec_model, a=1e-3):\n",
    "    \n",
    "    embedding_size = word2vec_model.vector_size\n",
    "    sentence_set = []\n",
    "\n",
    "    for sentence in sentence_list:\n",
    "        vs = np.zeros(embedding_size, dtype=np.float32)  # add all word2vec values into one vector for the sentence\n",
    "        word_tokens = sentence.split()\n",
    "        sentence_length = len(word_tokens)\n",
    "\n",
    "        for word in word_tokens:\n",
    "            a_value = a / (a + get_word_frequency(word, word2vec_model))  # smooth inverse frequency, SIF\n",
    "            vs = np.add(vs, np.multiply(a_value, get_word_vector(word, word2vec_model)))  # vs += sif * word_vector\n",
    "\n",
    "        vs = np.divide(vs, sentence_length)  # weighted average\n",
    "        sentence_set.append(vs)  # add to our existing re-calculated set of sentences\n",
    "\n",
    "    \n",
    "    # calculate PCA of this sentence set\n",
    "    pca = PCA(n_components=embedding_size)\n",
    "    pca.fit(np.array(sentence_set))\n",
    "    u = pca.components_[0]  # the PCA vector\n",
    "    u = np.multiply(u, np.transpose(u))  # u x uT\n",
    "\n",
    "    # pad the vector?  (occurs if we have less sentences than embeddings_size)\n",
    "    if len(u) < embedding_size:\n",
    "        for i in range(embedding_size - len(u)):\n",
    "            u = np.append(u, 0)  # add needed extension for multiplication below\n",
    "\n",
    "    # resulting sentence vectors, vs = vs -u x uT x vs\n",
    "    sentence_vecs = []\n",
    "    for vs in sentence_set:\n",
    "        sub = np.multiply(u, vs)\n",
    "        sentence_vecs.append(np.subtract(vs, sub).astype(np.float32))\n",
    "\n",
    "    return sentence_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_names = ['star_1', 'star_2', 'star_3', 'star_4','star_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\Program\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\Program\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\Program\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\Program\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "from six.moves import cPickle as pickle\n",
    "\n",
    "for star_name in star_names:\n",
    "    sentence_vectors = sentence_to_vec(new_df[star_name], zh_wiki_word2vec_model)\n",
    "    dataset = np.array(sentence_vectors)\n",
    "    set_filename = star_name + '.pickle'\n",
    "    try:\n",
    "        with open(set_filename, 'wb') as f:\n",
    "            pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as e:\n",
    "        print('Unable to save data to', set_filename, ':', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  4.Train neaual network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 按比例70 15 15 划分训练集，验证集，测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_names = ['star_1', 'star_2', 'star_3', 'star_4','star_5']\n",
    "pickle_files = []\n",
    "for star_name in star_names:\n",
    "    pickle_files.append(star_name + '.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of pictures in star_1.pickle =  (19873, 200)\n",
      "number of pictures in star_2.pickle =  (19873, 200)\n",
      "number of pictures in star_3.pickle =  (19873, 200)\n",
      "number of pictures in star_4.pickle =  (19873, 200)\n",
      "number of pictures in star_5.pickle =  (19873, 200)\n"
     ]
    }
   ],
   "source": [
    "for pickle_file in pickle_files:\n",
    "    with open(pickle_file, 'rb') as pk_f:\n",
    "        dat = pickle.load(pk_f)\n",
    "    print('number of pictures in {} = '.format(pickle_file), dat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_arrays(nb_rows, embedding_size):\n",
    "    dataset = np.ndarray((nb_rows, embedding_size), dtype=np.float32)\n",
    "    labels = np.ndarray(nb_rows, dtype=np.int32)\n",
    "    return dataset, labels\n",
    "\n",
    "def merge_datasets(pickle_files, embedding_size, sample_size_per_class, train_ratio, valid_ratio, test_ratio):\n",
    "    \n",
    "    train_size_per_class = int(sample_size_per_class * train_ratio)\n",
    "    valid_size_per_class = int(sample_size_per_class * valid_ratio)\n",
    "    test_size_per_class  = int(sample_size_per_class * test_ratio)\n",
    "\n",
    "    num_classes = len(pickle_files)\n",
    "    train_dataset, train_labels = make_arrays(train_size_per_class*num_classes, embedding_size)\n",
    "    valid_dataset, valid_labels = make_arrays(valid_size_per_class*num_classes, embedding_size)\n",
    "    test_dataset,   test_labels = make_arrays(test_size_per_class*num_classes, embedding_size)\n",
    "    \n",
    "    start_train, start_valid, start_test = 0, 0, 0\n",
    "    end_train, end_valid, end_test = train_size_per_class, valid_size_per_class, test_size_per_class\n",
    "    end_train_valid = train_size_per_class + valid_size_per_class\n",
    "    end_last = train_size_per_class + valid_size_per_class + test_size_per_class\n",
    "\n",
    "    for label, pickle_file in enumerate(pickle_files):\n",
    "        try:\n",
    "            with open(pickle_file, 'rb') as f:\n",
    "                letter_set = pickle.load(f)\n",
    "                # let's shuffle the letters to have random validation and training set\n",
    "                np.random.shuffle(letter_set)\n",
    "\n",
    "                train_letter = letter_set[:train_size_per_class, :]\n",
    "                train_dataset[start_train:end_train, :] = train_letter\n",
    "                train_labels[start_train:end_train] = label\n",
    "                start_train += train_size_per_class\n",
    "                end_train += train_size_per_class\n",
    "\n",
    "                valid_letter = letter_set[train_size_per_class:end_train_valid, :]\n",
    "                valid_dataset[start_valid:end_valid, :] = valid_letter\n",
    "                valid_labels[start_valid:end_valid] = label\n",
    "                start_valid += valid_size_per_class\n",
    "                end_valid += valid_size_per_class\n",
    "\n",
    "                test_letter = letter_set[end_train_valid:end_last, :]\n",
    "                test_dataset[start_test:end_test, :] = test_letter\n",
    "                test_labels[start_test:end_test] = label\n",
    "                start_test += test_size_per_class\n",
    "                end_test += test_size_per_class\n",
    "\n",
    "        except Exception as e:\n",
    "            print('Unable to process data from', pickle_file, ':', e)\n",
    "            raise\n",
    "    \n",
    "    return train_dataset, train_labels, valid_dataset, valid_labels, test_dataset, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (79490, 200) (79490,)\n",
      "Validation: (9935, 200) (9935,)\n",
      "Testing: (9935, 200) (9935,)\n"
     ]
    }
   ],
   "source": [
    "train_dataset, train_labels, valid_dataset, valid_labels, test_dataset, test_labels = merge_datasets(\n",
    "    pickle_files, 200, 19873, 0.8, 0.1, 0.1)\n",
    "\n",
    "print('Training:', train_dataset.shape, train_labels.shape)\n",
    "print('Validation:', valid_dataset.shape, valid_labels.shape)\n",
    "print('Testing:', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (79490, 200) (79490, 5)\n",
      "Validation set (9935, 200) (9935, 5)\n",
      "Test set (9935, 200) (9935, 5)\n"
     ]
    }
   ],
   "source": [
    "num_labels = 5\n",
    "\n",
    "def reformat(labels):\n",
    "    # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "    labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "    return labels\n",
    "train_labels = reformat(train_labels)\n",
    "valid_labels = reformat(valid_labels)\n",
    "test_labels = reformat(test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 构建tf graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = zh_wiki_word2vec_model.vector_size\n",
    "num_labels = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_nodes= 1024\n",
    "batch_size = 128\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, embedding_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "    # Variables.\n",
    "    weights_1 = tf.Variable(tf.truncated_normal([embedding_size, num_nodes]))\n",
    "    biases_1 = tf.Variable(tf.zeros([num_nodes]))\n",
    "    weights_2 = tf.Variable(tf.truncated_normal([num_nodes, num_labels]))\n",
    "    biases_2 = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    logits_1 = tf.matmul(tf_train_dataset, weights_1) + biases_1\n",
    "    relu_layer= tf.nn.relu(logits_1)\n",
    "    logits_2 = tf.matmul(relu_layer, weights_2) + biases_2\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits_2))\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    # Predictions for the training\n",
    "    train_prediction = tf.nn.softmax(logits_2)\n",
    "    \n",
    "    # Predictions for validation \n",
    "    logits_1 = tf.matmul(tf_valid_dataset, weights_1) + biases_1\n",
    "    relu_layer= tf.nn.relu(logits_1)\n",
    "    logits_2 = tf.matmul(relu_layer, weights_2) + biases_2\n",
    "    \n",
    "    valid_prediction = tf.nn.softmax(logits_2)\n",
    "    \n",
    "    # Predictions for test\n",
    "    logits_1 = tf.matmul(tf_test_dataset, weights_1) + biases_1\n",
    "    relu_layer= tf.nn.relu(logits_1)\n",
    "    logits_2 = tf.matmul(relu_layer, weights_2) + biases_2\n",
    "    \n",
    "    test_prediction = tf.nn.softmax(logits_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 1.6092209815979004\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 20.0%\n",
      "Minibatch loss at step 500: 0.8494643568992615\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 20.0%\n",
      "Minibatch loss at step 1000: 0.3035784661769867\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 20.0%\n",
      "Minibatch loss at step 1500: 0.28874245285987854\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 20.0%\n",
      "Minibatch loss at step 2000: 0.1566796749830246\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 20.0%\n",
      "Minibatch loss at step 2500: 0.11684799939393997\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 20.0%\n",
      "Minibatch loss at step 3000: 0.08830983191728592\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 20.0%\n",
      "Minibatch loss at step 3500: 0.0707460269331932\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 20.0%\n",
      "Minibatch loss at step 4000: 0.05901327729225159\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 20.0%\n",
      "Minibatch loss at step 4500: 0.05064419284462929\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 20.0%\n",
      "Minibatch loss at step 5000: 0.045521050691604614\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 20.0%\n",
      "Minibatch loss at step 5500: 0.040506161749362946\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 20.0%\n",
      "Minibatch loss at step 6000: 0.03638361394405365\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 20.0%\n",
      "Minibatch loss at step 6500: 0.03302823007106781\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 20.0%\n",
      "Minibatch loss at step 7000: 0.030252037569880486\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 20.0%\n",
      "Minibatch loss at step 7500: 0.02832333743572235\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 20.0%\n",
      "Minibatch loss at step 8000: 0.026337381452322006\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 20.0%\n",
      "Minibatch loss at step 8500: 0.02454034611582756\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 20.0%\n",
      "Minibatch loss at step 9000: 0.022975321859121323\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 20.0%\n",
      "Minibatch loss at step 9500: 0.02160489745438099\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 20.0%\n",
      "Minibatch loss at step 10000: 0.020590247586369514\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 20.0%\n",
      "Test accuracy: 20.0%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 10001\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step {}: {}\".format(step, l))\n",
    "            print(\"Minibatch accuracy: {:.1f}%\".format(accuracy(predictions, batch_labels)))\n",
    "            print(\"Validation accuracy: {:.1f}%\".format(accuracy(valid_prediction.eval(), valid_labels)))\n",
    "    print(\"Test accuracy: {:.1f}%\".format(accuracy(test_prediction.eval(), test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
